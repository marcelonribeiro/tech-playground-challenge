# üìä HR Analytics Platform

![Python Version](https://img.shields.io/badge/python-3.11-blue)
![Framework](https://img.shields.io/badge/flask-3.1.2-green)
![Coverage](https://img.shields.io/badge/coverage-85%25-brightgreen)
![Build Status](https://img.shields.io/badge/build-passing-success)
![Docker](https://img.shields.io/badge/docker-compose-orange)

Uma plataforma completa de **People Analytics** focada em transformar dados brutos de pesquisas de clima em intelig√™ncia acion√°vel. 

O sistema vai al√©m da visualiza√ß√£o b√°sica, implementando um pipeline de engenharia de dados robusto e utilizando **Intelig√™ncia Artificial (NLP)** para contrastar o que os colaboradores *dizem* (texto) versus como eles *pontuam* (scores).

---

## üìã Checklist de Tarefas Realizadas

O projeto foi desenvolvido para cobrir todas as exig√™ncias do desafio t√©cnico, incluindo os b√¥nus e explora√ß√µes criativas.

- [x] **Task 1: Basic Database** (Modelagem relacional no PostgreSQL 17 + SQLAlchemy 2.0: uso de √çndices (`index=True`) para otimiza√ß√£o de leitura e integra√ß√£o do `Flask-Migrate` (Alembic) para versionamento e evolu√ß√£o segura do esquema do banco sem perda de dados)
- [x] **Task 2: Basic Dashboard** (Interface web responsiva (Server-Side Rendering com Jinja2 + Bootstrap 5): filtros din√¢micos via URL (preservam estado ao compartilhar link) e UX moderna para dispositivos m√≥veis)
- [x] **Task 3: Test Suite** (Su√≠te de testes robusta utilizando pytest: cobertura de **85%**, abrangendo as 3 camadas da pir√¢mide: Unit√°rios (L√≥gica Matem√°tica), Integra√ß√£o (API/Status Codes) e L√≥gica de Neg√≥cio (Pipeline de Ingest√£o e IA))
- [x] **Task 4: Docker Compose Setup** (Orquestra√ß√£o completa de 5 servi√ßos: Web (Flask servido pelo gunicorn), Celery Worker, Celery Beat, Redis e Postgresql: `Dockerfile` Multi-stage para redu√ß√£o do tamanho da imagem final, que fica sem compiladores (j√° com os wheels prontos) e execu√ß√£o com usu√°rio n√£o-root (`appuser`) para seguran√ßa refor√ßada. Implementa√ß√£o de `Healthchecks` para garantir a ordem correta de inicializa√ß√£o (Web aguarda DB))
- [x] **Task 5: Exploratory Data Analysis** (A an√°lise explorat√≥ria foi automatizada diretamente nos Dashboards)
- [x] **Task 6: Visualization - Company Level** (Vis√£o focada em KPIs de convers√£o e distribui√ß√£o de tempo de casa (Tenure): implementa√ß√£o de Gr√°ficos de Radar comparativos para identificar lacunas culturais globais)
- [x] **Task 7: Visualization - Area Level** (Ferramenta de Benchmarking Cross-Department: Gr√°fico de Eixo Duplo (Dual Axis) que permite comparar Score Num√©rico (0-10) vs Sentimento da IA (1-5) lado a lado para todas as √°reas)
- [x] **Task 8: Visualization - Employee Level** (Perfil individual confidencial com busca: "Tri-Layer Radar Chart" que compara o Indiv√≠duo vs M√©dia do Depto vs M√©dia da Empresa num √∫nico gr√°fico visual, al√©m de an√°lise de sentimento espec√≠fica para o coment√°rio de eNPS)
- [x] **Task 9: Build a Simple API** (API RESTful segregada em Blueprint espec√≠fico: pagina√ß√£o, filtros via query params, serializa√ß√£o robusta com Pydantic (DTOs) e documenta√ß√£o interativa integrada (`/api-docs`))
- [x] **Task 10: Sentiment Analysis** (Pipeline de NLP usando HuggingFace Transformers (modelo `bert-base-multilingual-uncased-sentiment`), processamento Ass√≠ncrono (Celery) e l√≥gica de "Re-an√°lise Inteligente" (s√≥ roda IA se o texto mudar, economizando recursos computacionais))
- [x] **Task 11: Report Generation** (Funcionalidade de Export/Print em certos dashboards)
- [x] **Task 12: Creative Exploration** (An√°lise de "Perception Gap": Cria√ß√£o de m√©tricas comparativas e alertas visuais quando h√° discrep√¢ncia entre a nota dada pelo colaborador e o sentimento detectado pela IA)

---

## ‚ö° Quick Start

A aplica√ß√£o √© totalmente containerizada e utiliza um script de Auto-Bootstrap (`entrypoint.sh`). Ao subir os containers, o sistema automaticamente aguarda o banco, roda as migra√ß√µes, baixa os dados e executa a IA.

### 1. Clonar e Configurar
Clone o reposit√≥rio, entre na pasta e configure as vari√°veis de ambiente.

    git clone https://github.com/marcelonribeiro/tech-playground-challenge.git
    cd tech-playground-challenge
    
    # Cria o arquivo .env baseado no exemplo fornecido (Configura√ß√µes pr√©-definidas para Docker local)
    cp .env.example .env

### 2. Rodar a Aplica√ß√£o
Execute o comando abaixo. Isso ir√° construir as imagens, iniciar o Postgres, Redis, Celery (Worker+Beat) e a Aplica√ß√£o Web.

    docker-compose up --build

*Aguarde alguns segundos na primeira execu√ß√£o para o download do modelo de IA e o processamento inicial dos dados.*

### 3. Acessar

- **Dashboard:** [http://localhost:5000](http://localhost:5000)
- **API Docs:** [http://localhost:5000/api-docs](http://localhost:5000/api-docs)

### 4. Rodar os Testes

Para validar a qualidade do c√≥digo e ver o report de cobertura:

    docker-compose exec web pytest -v --cov=src --cov-report=html

---

## üèóÔ∏è Architecture Decision Records (ADR)

Decis√µes t√©cnicas tomadas visando um ciclo de vida de software longo, sustent√°vel e escal√°vel.

### 1. Framework: Flask
**Decis√£o:** Flask.
**Porqu√™:**
- **Flask vs Django:** Escolhi Flask por ser leve e flex√≠vel, permitindo selecionar as melhores bibliotecas para cada fun√ß√£o (SQLAlchemy, Pydantic, Alembic). Django traria "baterias" desnecess√°rias para este escopo.
- **Flask vs FastAPI:** Embora FastAPI seja excelente para APIs puras, o foco do projeto √© uma aplica√ß√£o Full-stack com Renderiza√ß√£o Server-Side (Jinja2) robusta e Dashboards integrados, onde o ecossistema Flask √© extremamente maduro. A API √© um complemento importante, mas n√£o o √∫nico produto.

### 2. Pipeline de Ingest√£o At√¥mico & Idempotente
**Decis√£o:** Pipeline unificado com detec√ß√£o de mudan√ßas (Hashing l√≥gico).
**Porqu√™:** Em sistemas de RH, o mesmo arquivo pode ser enviado v√°rias vezes com corre√ß√µes. O pipeline atende a requisitos de consist√™ncia:
- **Idempot√™ncia:** O pipeline verifica linha a linha. Se o dado n√£o mudou, ele pula (economiza processamento).
- **Atomicidade L√≥gica:** Utilizamos `db.session.flush()` para garantir que um registro s√≥ seja commitado no banco se a an√°lise de sentimento da IA tamb√©m tiver ocorrido. N√£o existem dados "meio processados".
- **Economia de Recursos:** Se o texto de um coment√°rio mudar, a IA roda novamente. Se apenas a nota mudar, a IA √© poupada. garante que o banco nunca tenha duplicatas e que a IA s√≥ rode quando estritamente necess√°rio (economia de recursos).

### 3. Processamento Ass√≠ncrono e Agendamento (Celery + Redis)
**Decis√£o:** Arquitetura de Workers separada com Agendamento (Beat).
**Porqu√™:** Automa√ß√£o (ETL). Utilizei o Celery Beat para agendar a atualiza√ß√£o dos dados diariamente. Isso simula um ambiente de produ√ß√£o onde os dados s√£o vivos e atualizados recorrentemente, eliminando a necessidade de ferramentas complexas como Airflow para este escopo espec√≠fico.

### 4. Modelo de Dados & Valida√ß√£o
**Decis√£o:** Pydantic para Ingest√£o (DTOs) vs SQLAlchemy para Persist√™ncia.
**Porqu√™:**
- **Pydantic**: Atua como "Guardrail" na entrada. Sanitiza os dados brutos do CSV (trata datas brasileiras `DD/MM/YYYY`, limpa strings vazias, valida e-mails) antes que eles toquem o dom√≠nio.
- **SQLAlchemy**: Garante a integridade referencial e tipagem no banco de dados.

### 5. Manipula√ß√£o de Dados (Pandas)
**Decis√£o**: Uso da biblioteca Pandas para a etapa de Extra√ß√£o e Transforma√ß√£o.
**Porqu√™:** Pandas √© o padr√£o da ind√∫stria para manipula√ß√£o tabular e limpeza de dados (Data Cleaning). Ele facilita a leitura de CSVs complexos e o pr√©-processamento em lote antes da itera√ß√£o de carga no banco.

### 6. Schema Evolution (Flask-Migrate)
**Decis√£o:** Uso de Migrations (Alembic).
**Porqu√™:** Projetos reais mudam. Comecei sem a tabela de sentimentos e depois a adicionei. O uso de `Flask-Migrate` permitiu evoluir o banco de dados sem perder os dados j√° ingeridos e sem precisar de "reset" manual, simulando um ambiente de produ√ß√£o real.

### 7. Integra√ß√£o Cont√≠nua (CI/CD)
**Decis√£o:** GitHub Actions.
**Porqu√™:** Optei por uma solu√ß√£o nativa e sem servidor (Serverless) para garantir a qualidade do c√≥digo.
- **Workflow:** Criamos um pipeline (`ci.yml`) que √© acionado automaticamente a cada *Push* ou *Pull Request* para a branch `main`.
- **Ambiente Isolado:** O Action provisiona um ambiente Ubuntu limpo e utiliza **Service Containers** para subir uma inst√¢ncia de Redis vol√°til, permitindo que os testes de integra√ß√£o do Celery rodem em um ambiente fiel √† produ√ß√£o.
- **Quality Gate:** O build falha se qualquer teste quebrar, impedindo que c√≥digo inst√°vel seja mesclado ao projeto.

### 8. An√°lise de Sentimentos
**Decis√£o:** O modelo `bert-base-multilingual-uncased-sentiment`.
**Porqu√™:** √â treinado em m√∫ltiplos idiomas, incluindo o Portugu√™s, capturando nuances sentimentais como positivo, negativo ou neutro com alta precis√£o. √â relativamente leve, com cerca de 168 milh√µes de par√¢metros, permitindo execu√ß√£o em hardware comum sem grande demanda computacional.

### 8. Framework CSS: Bootstrap vs Tailwind
**Decis√£o:** Bootstrap 5.
**Porqu√™:** O Bootstrap oferece consist√™ncia visual imediata e menor curva de aprendizado, reduzindo tempo de setup.

---

## üìÇ Estrutura do Projeto
O projeto segue os princ√≠pios de **Clean Architecture** simplificada, separando Dom√≠nio, Aplica√ß√£o e Interface.

    .
    ‚îú‚îÄ‚îÄ src/
    ‚îÇ   ‚îú‚îÄ‚îÄ application/            # L√≥gica de Neg√≥cio e Orquestra√ß√£o
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ services/           # Ingestion, Analytics, Dashboard, Sentiment
    ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ tasks/              # Celery Workers (Background Jobs)
    ‚îÇ   ‚îÇ
    ‚îÇ   ‚îú‚îÄ‚îÄ domain/                 # O Cora√ß√£o do Software
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ models.py           # Entidades do Banco (SQLAlchemy)
    ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ schemas.py          # Contratos de Dados (Pydantic)
    ‚îÇ   ‚îÇ
    ‚îÇ   ‚îú‚îÄ‚îÄ interface/              # Camada de Apresenta√ß√£o
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ api/                # REST API Endpoints
    ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ web/                # Views Endpoints para Frontend
    ‚îÇ   ‚îÇ
    ‚îÇ   ‚îú‚îÄ‚îÄ static/                 # Frontend (CSS/JS)
    ‚îÇ   ‚îú‚îÄ‚îÄ templates/              # Frontend (HTML/Jinja2)
    ‚îÇ   ‚îÇ
    ‚îÇ   ‚îú‚îÄ‚îÄ app.py                  # Application Factory
    ‚îÇ   ‚îú‚îÄ‚îÄ celery_app.py           # Entrypoint do Worker
    ‚îÇ   ‚îú‚îÄ‚îÄ config.py               # Configura√ß√µes de Ambiente
    ‚îÇ   ‚îî‚îÄ‚îÄ extensions.py           # Singletons (DB, Migrate, Celery)
    ‚îÇ
    ‚îú‚îÄ‚îÄ migrations/                 # Hist√≥rico de vers√µes do Banco (Alembic)
    |
    ‚îú‚îÄ‚îÄ tests/                      # Estrat√©gia de QA
    ‚îÇ   ‚îú‚îÄ‚îÄ integration/            # Testes de API e Pipeline Real
    ‚îÇ   ‚îî‚îÄ‚îÄ unit/                   # Testes de L√≥gica Matem√°tica e Mock AI
    ‚îÇ
    ‚îú‚îÄ‚îÄ docker-compose.yml          # Orquestra√ß√£o de Containers
    ‚îú‚îÄ‚îÄ Dockerfile                  # Defini√ß√£o de Imagem
    ‚îú‚îÄ‚îÄ entrypoint.sh               # Script de Inicializa√ß√£o (Auto-Heal & Bootstrap)
    ‚îú‚îÄ‚îÄ .env.example                # Template de vari√°veis de ambiente
    ‚îî‚îÄ‚îÄ requirements.txt            # Depend√™ncias

---

## üìö Documenta√ß√£o da API

O projeto exp√µe uma API RESTful completa. A documenta√ß√£o interativa e detalhada, incluindo exemplos de cURL e esquemas JSON, est√° dispon√≠vel localmente ap√≥s iniciar o projeto.

**Acesse:** [http://localhost:5000/api-docs](http://localhost:5000/api-docs)

### Principais Endpoints:
- `GET /api/v1/employees`: Listagem paginada com filtros.
- `GET /api/v1/dashboard/company`: M√©tricas executivas (eNPS, Turnover).
- `GET /api/v1/analytics/sentiment-overview`: Agrega√ß√£o de dados da IA.

---

## üß™ Testes e Qualidade

Segui uma pir√¢mide de testes para garantir robustez, atingindo cerca de 85% de cobertura do c√≥digo Python:

1. **Unit Tests:** Validam a l√≥gica matem√°tica dos dashboards (C√°lculo de eNPS, m√©dias) e o mapeamento da IA (ex: garantir que 1 estrela = NEGATIVO).
2. **Logic Tests:** Validam o pipeline de ingest√£o, garantindo que o sistema de Upsert n√£o duplica dados e que a IA √© acionada corretamente apenas quando necess√°rio (mockando chamadas externas).
3. **Integration Tests:** Validam o fluxo completo da API e Status Codes (200, 404, 500).

Para rodar com relat√≥rio de cobertura:

    docker-compose exec web pytest --cov=src --cov-report=html

---

## üß† Processo de Pensamento & Decis√µes

Mais do que entregar c√≥digo, este projeto reflete minha abordagem de **Engenharia de Produto**. Abaixo, detalho como priorizei e tomei decis√µes durante o desenvolvimento.

### 1. An√°lise e Prioriza√ß√£o (The "Why")

Ao receber o dataset, percebi que o maior valor n√£o estava nos n√∫meros isolados, mas na correla√ß√£o entre eles.

- **Problema:** Um eNPS de 8 √© bom? Depende. Se o coment√°rio diz "Gosto das pessoas, mas odeio o sal√°rio", o 8 mascara um risco de *churn*.
- **Decis√£o:** Priorizei a constru√ß√£o de um Pipeline de NLP robusto antes mesmo de fazer o primeiro gr√°fico. Se o dado n√£o fosse enriquecido na entrada, o dashboard seria apenas "mais do mesmo".

### 2. Arquitetura Evolutiva (The "How")

N√£o tentei fazer tudo de uma vez. Adotei uma abordagem iterativa:

1. **Funda√ß√£o:** Garanti que o banco (Postgres) e a ingest√£o (Pandas) fossem s√≥lidos. Se a ingest√£o falha, o app n√£o tem prop√≥sito.
2. **Qualidade:** Implementei testes automatizados cedo. Isso me deu seguran√ßa para refatorar o c√≥digo de ingest√£o para o modelo de "Upsert At√¥mico" sem medo de quebrar a l√≥gica existente.
3. **Experi√™ncia:** Deixei o Frontend por √∫ltimo, pois a UI deve ser apenas um reflexo de dados bem estruturados.

### 3. Foco no Usu√°rio Final (UX de Dados)

Ao desenhar os dashboards, pensei na jornada do RH:

- **Macro:** "Como est√° a empresa?" -> *Dashboard Company*
- **Meso:** "Qual time precisa de ajuda?" -> *Dashboard Areas (Comparativo)*
- **Micro:** "Quem eu preciso entrevistar hoje?" -> *Dashboard Employee (Perfil)*

Por isso, implementei o **Gr√°fico de Eixo Duplo** (Task 7) e os **Radares Comparativos** (Task 8), para que o usu√°rio n√£o precise fazer contas de cabe√ßa.

---

## ü§ñ Uso de IA no Desenvolvimento

Seguindo a sugest√£o do case, utilizei LLMs (Large Language Models) como um **Copiloto S√™nior** para acelerar o desenvolvimento. Aqui est√° sobre onde a IA atuou:

### Onde a IA foi utilizada (Acelera√ß√£o):

- **Boilerplate e Scaffolding:** Gera√ß√£o inicial de classes Pydantic baseadas nas colunas do CSV (economizando tempo de digita√ß√£o repetitiva).
- **Frontend (Bootstrap/Chart.js):** Cria√ß√£o r√°pida de estruturas HTML responsivas e configura√ß√µes complexas de gr√°ficos (ex: configura√ß√µes de eixos do Chart.js).
- **Refatora√ß√£o:** Sugest√µes para limpar importa√ß√µes e tipagem (Type Hinting) em arquivos longos.

### Onde a IA N√ÉO foi utilizada (Engenharia Real):

- **Decis√µes Arquiteturais:** A escolha de usar *Application Factory*, a estrat√©gia de *Atomic Upsert* no banco e a separa√ß√£o de *Services* foi decis√£o minha baseada em experi√™ncia com sistemas escal√°veis.
- **Debug Complexo:** A resolu√ß√£o de *Race Conditions* no Docker (entrypoint) e *Circular Imports* no Celery exigiu entendimento profundo do funcionamento interno do Python/Linux, onde a IA muitas vezes sugere solu√ß√µes gen√©ricas que n√£o funcionam.

A IA atuou como um multiplicador de produtividade, permitindo que eu focasse na **Arquitetura e no Produto**, enquanto ela cuidava da sintaxe e da repeti√ß√£o.

---

**Desenvolvido por Marcelo Nunes Ribeiro** - 2026